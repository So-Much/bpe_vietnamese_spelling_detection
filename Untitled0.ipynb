{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNmBHZijsLNEyeZReszdZT6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"e5Ymbh1kSbTC"},"outputs":[],"source":["# Pandas\n","import pandas as pd\n","\n","# pyvi\n","# !pip install pyvi\n","from pyvi import ViTokenizer\n","\n","#nltk\n","import nltk\n","\n","import re\n","\n","# Sklearn\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","\n","\n","# ast\n","from ast import literal_eval\n","\n","# Underthesea\n","# !pip install underthesea\n","from underthesea import word_tokenize\n","\n","# Tensorflow\n","import tensorflow as tf\n","# !pip install tensorflow_hub\n","import tensorflow_hub as hub\n","from transformers import TFBertForSequenceClassification\n","\n","# PyTorch\n","import torch\n","from transformers import BertForSequenceClassification\n","\n","# Keras\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Conv1D, MaxPooling1D, Flatten, Dense\n","from sklearn.preprocessing import LabelEncoder\n","from keras.utils import to_categorical\n","\n","\n","# matplotlib to draw\n","import matplotlib.pyplot as plt\n","\n","# Time using for check duration of training\n","import time\n","\n","# Base Model\n","from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn import linear_model\n","from sklearn import svm\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.multioutput import MultiOutputClassifier\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n"]},{"cell_type":"code","source":["# split data\n","input_ = dataset['train']['input_text']\n","target_text = dataset['train']['target_text']\n","target_label = dataset['train']['general_error_type']\n","\n","tokenizer = BPE()\n","# tokenizer.fit_on_text(corpus=dataset['train']['input_text'], vocab_size=max_vocab_size)\n","# tokenizer.save_vocab(vocab_stored_path)\n","\n","tokenizer.load_vocab(vocab_stored_path)"],"metadata":{"id":"nRI5XkFz0tVU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tạo OneHotEncoder và biến đổi các tokens thành vector One-Hot\n","onehot_encoder = OneHotEncoder(sparse=False)\n","tokens_array = np.array(tokens).reshape(-1, 1)\n","onehot_encoded = onehot_encoder.fit_transform(tokens_array)"],"metadata":{"id":"bNjSCfuS4Lsz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from gensim.models import Word2Vec\n","\n","# Giả sử bạn có các tokens từ các câu (danh sách các danh sách tokens)\n","sentences = [['I', 'love', 'machine', 'learning'], ['Do', 'you', 'like', 'machine', 'learning'], ['Machine', 'learning', 'is', 'fun']]\n","\n","# Huấn luyện mô hình Word2Vec\n","model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)"],"metadata":{"id":"CkYvKLTQ4S_k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tạo TF-IDF vectorizer và biến đổi các câu thành các vector TF-IDF\n","vectorizer = TfidfVectorizer()\n","\n","X = vectorizer.fit_transform(sentences)\n","X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)"],"metadata":{"id":"KTBTFfzL3haB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-base-uncased')\n"],"metadata":{"id":"3ViLLC283rnj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(tokens = [], labels = None, model = None):\n","  X_train, X_test, y_train, y_test = train_test_split(tokens,label,random_state=42,\n","                                                    test_size=0.25)\n","  start_time = time.time()\n","  model.fit(X_train, y_train)\n","  end_time = time.time()\n","  y_pred = model.predict(X_test)\n","  print('Model: ', model)\n","  print(classification_report(y_test, y_pred))\n","  train_time = end_time - start_time\n","  print(\"Trained time:\", train_time, \"seconds\")\n","  print('=+'*40)"],"metadata":{"id":"dH71BIrl3umI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["models = [MultinomialNB() ,GaussianNB() , BernoulliNB(), DecisionTreeClassifier(), KNeighborsClassifier(), LogisticRegression(), RandomForestClassifier()]\n","for model in models:\n","  train(tokens, labels, model)"],"metadata":{"id":"70J9SFju604Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EBuzsc667ES5"},"execution_count":null,"outputs":[]}]}